{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Title\n",
    "\n",
    "This notebook lists all the steps that you need to complete the complete this project. You will need to complete all the TODOs in this notebook as well as in the README and the two python scripts included with the starter code.\n",
    "\n",
    "\n",
    "**TODO**: Give a helpful introduction to what this notebook is for. Remember that comments, explanations and good documentation make your project informative and professional.\n",
    "\n",
    "**Note:** This notebook has a bunch of code and markdown cells with TODOs that you have to complete. These are meant to be helpful guidelines for you to finish your project while meeting the requirements in the project rubrics. Feel free to change the order of these the TODO's and use more than one TODO code cell to do all your tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: smdebug in /opt/conda/lib/python3.6/site-packages (1.0.9)\n",
      "Requirement already satisfied: boto3>=1.10.32 in /opt/conda/lib/python3.6/site-packages (from smdebug) (1.20.24)\n",
      "Requirement already satisfied: pyinstrument>=3.1.3 in /opt/conda/lib/python3.6/site-packages (from smdebug) (3.4.2)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /opt/conda/lib/python3.6/site-packages (from smdebug) (3.19.1)\n",
      "Requirement already satisfied: numpy>=1.16.0 in /opt/conda/lib/python3.6/site-packages (from smdebug) (1.19.1)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.6/site-packages (from smdebug) (21.3)\n",
      "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /opt/conda/lib/python3.6/site-packages (from boto3>=1.10.32->smdebug) (0.5.0)\n",
      "Requirement already satisfied: botocore<1.24.0,>=1.23.24 in /opt/conda/lib/python3.6/site-packages (from boto3>=1.10.32->smdebug) (1.23.24)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/lib/python3.6/site-packages (from boto3>=1.10.32->smdebug) (0.10.0)\n",
      "Requirement already satisfied: pyinstrument-cext>=0.2.2 in /opt/conda/lib/python3.6/site-packages (from pyinstrument>=3.1.3->smdebug) (0.2.4)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.6/site-packages (from packaging->smdebug) (3.0.6)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/conda/lib/python3.6/site-packages (from botocore<1.24.0,>=1.23.24->boto3>=1.10.32->smdebug) (1.26.6)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.6/site-packages (from botocore<1.24.0,>=1.23.24->boto3>=1.10.32->smdebug) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.6/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.24.0,>=1.23.24->boto3>=1.10.32->smdebug) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# TODO: Install any packages that you might need\n",
    "# For instance, you will need the smdebug package\n",
    "!pip install smdebug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-01-23 11:11:14.699 pytorch-1-8-gpu-py3-ml-g4dn-xlarge-60bd0d07a83be181dcf7335baae2:30 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n"
     ]
    }
   ],
   "source": [
    "# TODO: Import any packages that you might need\n",
    "# For instance you will need Boto3 and Sagemaker\n",
    "import sagemaker\n",
    "import boto3\n",
    "\n",
    "#Hyperparameter tuning\n",
    "import sagemaker\n",
    "from sagemaker.tuner import (\n",
    "    IntegerParameter,\n",
    "    CategoricalParameter,\n",
    "    ContinuousParameter,\n",
    "    HyperparameterTuner,\n",
    ")\n",
    "\n",
    "#Estimator\n",
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "#Debugger and Profiler\n",
    "from sagemaker.debugger import Rule, ProfilerRule, rule_configs\n",
    "from sagemaker.debugger import DebuggerHookConfig, ProfilerConfig, FrameworkProfile\n",
    "from smdebug.trials import create_trial\n",
    "from smdebug.core.modes import ModeKeys\n",
    "\n",
    "#Plotting Debug Report\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import host_subplot\n",
    "\n",
    "#Display Profiler Report\n",
    "import os\n",
    "import IPython\n",
    "\n",
    "#Import Data for Query\n",
    "import gzip \n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "\n",
    "#Setup\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "prefix = \"sagemaker/project-pytorch-cifar\"\n",
    "\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "TODO: Explain what dataset you are using for this project. Maybe even give a small overview of the classes, class distributions etc that can help anyone not familiar with the dataset get a better understand of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "input spec (in this case, just an S3 path): s3://sagemaker-us-east-1-690938509668/sagemaker/project-pytorch-cifar\n"
     ]
    }
   ],
   "source": [
    "#TODO: Fetch and upload the data to AWS S3\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import CIFAR10\n",
    "\n",
    "\n",
    "local_dir = 'data'\n",
    "CIFAR10.mirrors = [\"https://sagemaker-sample-files.s3.amazonaws.com/datasets/image/CIFAR10/\"]\n",
    "CIFAR10(\n",
    "    local_dir,\n",
    "    download=True,\n",
    "    transform=transforms.Compose(\n",
    "        [transforms.ToTensor()]\n",
    "    )\n",
    ")\n",
    "\n",
    "inputs = sagemaker_session.upload_data(path=local_dir, bucket=bucket, key_prefix=prefix)\n",
    "print(\"input spec (in this case, just an S3 path): {}\".format(inputs))\n",
    "\n",
    "# # Command to download and unzip data\n",
    "# !wget https://s3-us-west-1.amazonaws.com/udacity-aind/dog-project/dogImages.zip\n",
    "# !unzip dogImages.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning\n",
    "**TODO:** This is the part where you will finetune a pretrained model with hyperparameter tuning. Remember that you have to tune a minimum of two hyperparameters. However you are encouraged to tune more. You are also encouraged to explain why you chose to tune those particular hyperparameters and the ranges.\n",
    "\n",
    "**Note:** You will need to use the `hpo.py` script to perform hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Declare your HP ranges, metrics etc.\n",
    "hyperparameter_ranges = {\n",
    "    \"lr\": ContinuousParameter(0.001, 0.1),\n",
    "    \"batch-size\": CategoricalParameter([10, 32]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Create estimators for your HPs\n",
    "# rules = [\n",
    "#     Rule.sagemaker(rule_configs.loss_not_decreasing()),\n",
    "#     ProfilerRule.sagemaker(rule_configs.ProfilerReport()),\n",
    "#     Rule.sagemaker(rule_configs.vanishing_gradient()),\n",
    "#     Rule.sagemaker(rule_configs.overfit()),\n",
    "#     Rule.sagemaker(rule_configs.overtraining()),\n",
    "#     Rule.sagemaker(rule_configs.poor_weight_initialization()),\n",
    "# ]\n",
    "# profiler_config = ProfilerConfig(\n",
    "#     system_monitor_interval_millis=500, framework_profile_params=FrameworkProfile(num_steps=10)\n",
    "# )\n",
    "# debugger_config = DebuggerHookConfig(\n",
    "#     hook_parameters={\"train.save_interval\": \"100\", \"eval.save_interval\": \"10\"}\n",
    "# )\n",
    "estimator = PyTorch(\n",
    "    entry_point=\"./train_model.py\",\n",
    "    role=role,\n",
    "    py_version='py36',\n",
    "    framework_version=\"1.8\",\n",
    "#     hyperparameters={\"epochs\": \"2\", \"batch-size\": \"32\", \"test-batch-size\": \"100\", \"lr\": \"0.001\"},\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.large\",\n",
    "#     profiler_config = profiler_config,\n",
    "#     debugger_hook_config = debugger_config,\n",
    "#     rules = rules\n",
    ")# TODO: Your estimator here\n",
    "\n",
    "objective_metric_name = \"average test loss\"\n",
    "objective_type = \"Minimize\"\n",
    "metric_definitions = [{\n",
    "    \"Name\": \"average test loss\",\n",
    "    \"Regex\": \"Testing Loss: ([0-9\\\\.]+)\"\n",
    "}]\n",
    "tuner = HyperparameterTuner(\n",
    "    estimator,\n",
    "    objective_metric_name,\n",
    "    hyperparameter_ranges,\n",
    "    metric_definitions,\n",
    "    max_jobs=4,\n",
    "    max_parallel_jobs=2,\n",
    "    objective_type=objective_type\n",
    ")# TODO: Your HP tuner here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating hyperparameter tuning job with name: pytorch-training-220123-0718\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................."
     ]
    }
   ],
   "source": [
    "# TODO: Fit your HP Tuner\n",
    "tuner.fit({\"training\": inputs}, wait=True) # TODO: Remember to include your data channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'epochs': '\"2\"',\n",
       " 'batch-size': '\"32\"',\n",
       " 'test-batch-size': '\"100\"',\n",
       " 'lr': '\"0.001\"'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Get the best estimators and the best HPs\n",
    "# best_training_name = 'pytorch-training-220123-0718'\n",
    "# tuner.attach(best_training_name)\n",
    "best_estimator = tuner.best_estimator()#TODO\n",
    "\n",
    "#Get the hyperparameters of the best trained model\n",
    "best_estimator.hyperparameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Profiling and Debugging\n",
    "TODO: Using the best hyperparameters, create and finetune a new model\n",
    "\n",
    "**Note:** You will need to use the `train_model.py` script to perform model profiling and debugging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Set up debugging and profiling rules and hooks\n",
    "rules = [\n",
    "    Rule.sagemaker(rule_configs.loss_not_decreasing()),\n",
    "    ProfilerRule.sagemaker(rule_configs.ProfilerReport()),\n",
    "]\n",
    "profiler_config = ProfilerConfig(\n",
    "    system_monitor_interval_millis=500, framework_profile_params=FrameworkProfile(num_steps=10)\n",
    ")\n",
    "debugger_config = DebuggerHookConfig(\n",
    "    hook_parameters={\"train.save_interval\": \"100\", \"eval.save_interval\": \"10\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating training-job with name: pytorch-training-2022-01-23-11-15-52-475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-23 11:15:52 Starting - Starting the training job...\n",
      "2022-01-23 11:16:23 Starting - Launching requested ML instancesLossNotDecreasing: InProgress\n",
      "ProfilerReport: InProgress\n",
      "......\n",
      "2022-01-23 11:17:23 Starting - Preparing the instances for training.........\n",
      "2022-01-23 11:18:45 Downloading - Downloading input data...\n",
      "2022-01-23 11:19:23 Training - Downloading the training image...\n",
      "2022-01-23 11:19:48 Training - Training image download completed. Training in progress..\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2022-01-23 11:19:50,234 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2022-01-23 11:19:50,236 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-01-23 11:19:50,245 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2022-01-23 11:19:50,251 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2022-01-23 11:19:50,652 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-01-23 11:19:50,667 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-01-23 11:19:50,678 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-01-23 11:19:50,687 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"batch-size\": \"32\",\n",
      "        \"test-batch-size\": \"100\",\n",
      "        \"lr\": \"0.001\",\n",
      "        \"epochs\": \"2\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"pytorch-training-2022-01-23-11-15-52-475\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-690938509668/pytorch-training-2022-01-23-11-15-52-475/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train_model\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 2,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train_model.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"batch-size\":\"32\",\"epochs\":\"2\",\"lr\":\"0.001\",\"test-batch-size\":\"100\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train_model.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train_model\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=2\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-690938509668/pytorch-training-2022-01-23-11-15-52-475/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"batch-size\":\"32\",\"epochs\":\"2\",\"lr\":\"0.001\",\"test-batch-size\":\"100\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"pytorch-training-2022-01-23-11-15-52-475\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-690938509668/pytorch-training-2022-01-23-11-15-52-475/source/sourcedir.tar.gz\",\"module_name\":\"train_model\",\"network_interface_name\":\"eth0\",\"num_cpus\":2,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train_model.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--batch-size\",\"32\",\"--epochs\",\"2\",\"--lr\",\"0.001\",\"--test-batch-size\",\"100\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_BATCH-SIZE=32\u001b[0m\n",
      "\u001b[34mSM_HP_TEST-BATCH-SIZE=100\u001b[0m\n",
      "\u001b[34mSM_HP_LR=0.001\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=2\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.6 train_model.py --batch-size 32 --epochs 2 --lr 0.001 --test-batch-size 100\u001b[0m\n",
      "\u001b[34m[2022-01-23 11:19:52.542 algo-1:27 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2022-01-23 11:19:53.074 algo-1:27 INFO profiler_config_parser.py:102] Using config at /opt/ml/input/config/profilerconfig.json.\u001b[0m\n",
      "\u001b[34mFiles already downloaded and verified\u001b[0m\n",
      "\u001b[34mFiles already downloaded and verified\u001b[0m\n",
      "\u001b[34m[2022-01-23 11:19:55.966 algo-1:27 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2022-01-23 11:19:55.968 algo-1:27 INFO hook.py:201] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2022-01-23 11:19:55.969 algo-1:27 INFO hook.py:255] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2022-01-23 11:19:55.969 algo-1:27 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34mSTART TRAINING\u001b[0m\n",
      "\u001b[34mfitting 0\u001b[0m\n",
      "\u001b[34m[2022-01-23 11:19:56.084 algo-1:27 INFO hook.py:591] name:fc.0.weight count_params:5120\u001b[0m\n",
      "\u001b[34m[2022-01-23 11:19:56.085 algo-1:27 INFO hook.py:591] name:fc.0.bias count_params:10\u001b[0m\n",
      "\u001b[34m[2022-01-23 11:19:56.085 algo-1:27 INFO hook.py:593] Total Trainable Params: 5130\u001b[0m\n",
      "\u001b[34m[2022-01-23 11:19:56.086 algo-1:27 INFO hook.py:425] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m[2022-01-23 11:19:56.087 algo-1:27 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/27-algo-1/prestepzero-*-start-1642936793074866.8_train-0-stepstart-1642936796086887.5/python_stats.\u001b[0m\n",
      "\u001b[34m[2022-01-23 11:19:56.104 algo-1:27 INFO hook.py:488] Hook is writing from the hook with pid: 27\u001b[0m\n",
      "\u001b[34m[2022-01-23 11:19:58.263 algo-1:27 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/27-algo-1/train-0-stepstart-1642936796098724.0_train-0-forwardpassend-1642936798262638.5/python_stats.\u001b[0m\n",
      "\u001b[34m[2022-01-23 11:19:58.368 algo-1:27 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/27-algo-1/train-0-forwardpassend-1642936798265499.0_train-1-stepstart-1642936798365017.5/python_stats.\u001b[0m\n",
      "\u001b[34m[2022-01-23 11:20:09.004 algo-1:27 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/27-algo-1/train-1-stepstart-1642936798373350.5_train-1-forwardpassend-1642936809003632.0/python_stats.\u001b[0m\n",
      "\u001b[34m[2022-01-23 11:20:09.078 algo-1:27 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/27-algo-1/train-1-forwardpassend-1642936809006350.2_train-2-stepstart-1642936809076836.2/python_stats.\u001b[0m\n",
      "\u001b[34m[2022-01-23 11:20:18.165 algo-1:27 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/27-algo-1/train-2-stepstart-1642936809080583.2_train-2-forwardpassend-1642936818164669.8/python_stats.\u001b[0m\n",
      "\u001b[34m[2022-01-23 11:20:18.239 algo-1:27 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/27-algo-1/train-2-forwardpassend-1642936818166484.0_train-3-stepstart-1642936818236404.8/python_stats.\u001b[0m\n",
      "\u001b[34m[2022-01-23 11:20:27.426 algo-1:27 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/27-algo-1/train-3-stepstart-1642936818242213.8_train-3-forwardpassend-1642936827425734.0/python_stats.\u001b[0m\n",
      "\u001b[34m[2022-01-23 11:20:27.499 algo-1:27 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/27-algo-1/train-3-forwardpassend-1642936827427996.0_train-4-stepstart-1642936827498722.0/python_stats.\u001b[0m\n",
      "\u001b[34m[2022-01-23 11:20:36.162 algo-1:27 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/27-algo-1/train-4-stepstart-1642936827502054.0_train-4-forwardpassend-1642936836162273.8/python_stats.\u001b[0m\n",
      "\u001b[34m[2022-01-23 11:20:36.240 algo-1:27 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/27-algo-1/train-4-forwardpassend-1642936836164249.8_train-5-stepstart-1642936836239679.5/python_stats.\u001b[0m\n",
      "\u001b[34m[2022-01-23 11:20:45.193 algo-1:27 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/27-algo-1/train-5-stepstart-1642936836244981.8_train-5-forwardpassend-1642936845193483.2/python_stats.\u001b[0m\n",
      "\u001b[34m[2022-01-23 11:20:45.272 algo-1:27 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/27-algo-1/train-5-forwardpassend-1642936845195330.5_train-6-stepstart-1642936845268822.0/python_stats.\u001b[0m\n",
      "\u001b[34m[2022-01-23 11:20:54.315 algo-1:27 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/27-algo-1/train-6-stepstart-1642936845274961.2_train-6-forwardpassend-1642936854314983.2/python_stats.\u001b[0m\n",
      "\u001b[34m[2022-01-23 11:20:54.389 algo-1:27 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/27-algo-1/train-6-forwardpassend-1642936854317506.0_train-7-stepstart-1642936854388496.0/python_stats.\u001b[0m\n",
      "\u001b[34m[2022-01-23 11:21:03.650 algo-1:27 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/27-algo-1/train-7-stepstart-1642936854392157.5_train-7-forwardpassend-1642936863649647.5/python_stats.\u001b[0m\n",
      "\u001b[34m[2022-01-23 11:21:03.725 algo-1:27 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/27-algo-1/train-7-forwardpassend-1642936863651688.2_train-8-stepstart-1642936863724314.8/python_stats.\u001b[0m\n",
      "\u001b[34m[2022-01-23 11:21:12.968 algo-1:27 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/27-algo-1/train-8-stepstart-1642936863727887.2_train-8-forwardpassend-1642936872967828.0/python_stats.\u001b[0m\n",
      "\u001b[34m[2022-01-23 11:21:13.069 algo-1:27 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/27-algo-1/train-8-forwardpassend-1642936872969818.2_train-9-stepstart-1642936873062337.0/python_stats.\u001b[0m\n",
      "\u001b[34m[2022-01-23 11:21:21.966 algo-1:27 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/27-algo-1/train-9-stepstart-1642936873071691.0_train-9-forwardpassend-1642936881966580.5/python_stats.\u001b[0m\n",
      "\u001b[34m[2022-01-23 11:21:22.037 algo-1:27 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/27-algo-1/train-9-forwardpassend-1642936881968476.5_train-10-stepstart-1642936882036811.2/python_stats.\u001b[0m\n",
      "\u001b[34mfitting 100\u001b[0m\n",
      "\u001b[34mfitting 200\u001b[0m\n",
      "\u001b[34mfitting 300\u001b[0m\n",
      "\u001b[34mfitting 400\u001b[0m\n",
      "\u001b[34mfitting 500\u001b[0m\n",
      "\u001b[34mfitting 600\u001b[0m\n",
      "\u001b[34mfitting 700\u001b[0m\n",
      "\u001b[34mfitting 800\u001b[0m\n",
      "\u001b[34mfitting 900\u001b[0m\n",
      "\u001b[34mfitting 1000\u001b[0m\n",
      "\u001b[34mfitting 1100\u001b[0m\n",
      "\u001b[34mfitting 1200\u001b[0m\n",
      "\u001b[34mfitting 1300\u001b[0m\n",
      "\u001b[34mfitting 1400\u001b[0m\n",
      "\u001b[34mfitting 1500\u001b[0m\n",
      "\u001b[34mSTART VALIDATING\u001b[0m\n",
      "\u001b[34mEpoch 0: train loss 1264.854, val loss 157.150\u001b[0m\n",
      "\u001b[34mSTART TRAINING\u001b[0m\n",
      "\u001b[34mfitting 0\u001b[0m\n",
      "\u001b[34mfitting 100\u001b[0m\n",
      "\u001b[34mfitting 200\u001b[0m\n",
      "\u001b[34mfitting 300\u001b[0m\n",
      "\u001b[34mfitting 400\u001b[0m\n",
      "\u001b[34mfitting 500\u001b[0m\n",
      "\u001b[34mfitting 600\u001b[0m\n",
      "\u001b[34mfitting 700\u001b[0m\n",
      "\u001b[34mfitting 800\u001b[0m\n",
      "\u001b[34mfitting 900\u001b[0m\n",
      "\u001b[34mfitting 1000\u001b[0m\n",
      "\u001b[34mfitting 1100\u001b[0m\n",
      "\u001b[34mfitting 1200\u001b[0m\n",
      "\u001b[34mfitting 1300\u001b[0m\n",
      "\u001b[34mfitting 1400\u001b[0m\n",
      "\u001b[34mfitting 1500\u001b[0m\n",
      "\u001b[34mSTART VALIDATING\u001b[0m\n",
      "\u001b[34mEpoch 1: train loss 1003.582, val loss 159.926\u001b[0m\n",
      "\u001b[34mTesting Accuracy: 49.36\u001b[0m\n",
      "\u001b[34mTesting Loss: 1.6182724857330322\u001b[0m\n",
      "\u001b[34mSaving the model.\u001b[0m\n",
      "\u001b[34mDownloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-5c106cde.pth\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0.00/44.7M [00:00<?, ?B/s]#015 17%|█▋        | 7.70M/44.7M [00:00<00:00, 80.8MB/s]#015 36%|███▌      | 16.1M/44.7M [00:00<00:00, 85.0MB/s]#015 54%|█████▍    | 24.2M/44.7M [00:00<00:00, 81.6MB/s]#015 73%|███████▎  | 32.7M/44.7M [00:00<00:00, 84.3MB/s]#015 92%|█████████▏| 41.1M/44.7M [00:00<00:00, 85.8MB/s]#015100%|██████████| 44.7M/44.7M [00:00<00:00, 83.8MB/s]\u001b[0m\n",
      "\u001b[34m2022-01-23 13:26:29,436 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2022-01-23 13:26:44 Uploading - Uploading generated training model\n",
      "2022-01-23 13:26:44 Completed - Training job completed\n",
      "Training seconds: 7684\n",
      "Billable seconds: 7684\n"
     ]
    }
   ],
   "source": [
    "# TODO: Create and fit an estimator\n",
    "\n",
    "estimator = best_estimator# TODO: Your estimator here\n",
    "estimator.profiler_config = profiler_config\n",
    "estimator.debugger_hook_config = debugger_config\n",
    "estimator.rules = rules\n",
    "estimator.fit({\"training\":inputs}, wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-12-fc7841810795>, line 15)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-12-fc7841810795>\"\u001b[0;36m, line \u001b[0;32m15\u001b[0m\n\u001b[0;31m    steps_train, vals_train =\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# TODO: Plot a debugging output.\n",
    "ob_name = estimator.latest_training_job.name\n",
    "client = estimator.sagemaker_session.sagemaker_client\n",
    "description = client.describe_training_job(TrainingJobName=estimator.latest_training_job.name)\n",
    "trial = create_trial(estimator.latest_job_debugger_artifacts_path())\n",
    "def get_data(trial, tname, mode):\n",
    "    tensor = trial.tensor(tname)\n",
    "    steps = tensor.steps(mode=mode)\n",
    "    vals = []\n",
    "    for s in steps:\n",
    "        vals.append(tensor.value(s, mode=mode))\n",
    "    return steps, vals\n",
    "def plot_tensor(trial, tensor_name):\n",
    "\n",
    "    steps_train, vals_train = get_data(trial, tensor_name, mode=ModeKeys.TRAIN)\n",
    "    print(\"loaded TRAIN data\")\n",
    "    steps_eval, vals_eval = get_data(trial, tensor_name, mode=ModeKeys.EVAL)\n",
    "    print(\"loaded EVAL data\")\n",
    "    \n",
    "    (trial, tensor_name, mode=ModeKeys.TRAIN)\n",
    "    print(\"loaded TRAIN data\")\n",
    "    steps_eval, vals_eval = get_data(trial, tensor_name, mode=ModeKeys.EVAL)\n",
    "    print(\"loaded EVAL data\")\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 7))\n",
    "    host = host_subplot(111)\n",
    "\n",
    "    par = host.twiny()\n",
    "\n",
    "    host.set_xlabel(\"Steps (TRAIN)\")\n",
    "    par.set_xlabel(\"Steps (EVAL)\")\n",
    "    host.set_ylabel(tensor_name)\n",
    "\n",
    "    (p1,) = host.plot(steps_train, vals_train, label=tensor_name)\n",
    "    print(\"completed TRAIN plot\")\n",
    "    (p2,) = par.plot(steps_eval, vals_eval, label=\"val_\" + tensor_name)\n",
    "    print(\"completed EVAL plot\")\n",
    "    leg = plt.legend()\n",
    "\n",
    "    host.xaxis.get_label().set_color(p1.get_color())\n",
    "    leg.texts[0].set_color(p1.get_color())\n",
    "\n",
    "    par.xaxis.get_label().set_color(p2.get_color())\n",
    "    leg.texts[1].set_color(p2.get_color())\n",
    "\n",
    "    plt.ylabel(tensor_name)\n",
    "\n",
    "    plt.show()\n",
    "plot_tensor(trial, trial.tensor_names()[0])\n",
    "\n",
    "# TODO: Can you print the names of all the tensors that were tracked\n",
    "# TODO: Can you print the number of datapoints for one of those tensors\n",
    "# for both train and eval mode\n",
    "# print(trial.tensor_names())\n",
    "# len(trial.tensor(trial.tensor_names()[1]).steps(mode=ModeKeys.TRAIN))\n",
    "# len(trial.tensor(trial.tensor_names()[1]).steps(mode=ModeKeys.EVAL))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**: Is there some anomalous behaviour in your debugging output? If so, what is the error and how will you fix it?  \n",
    "**TODO**: If not, suppose there was an error. What would that error look like and how would you have fixed it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Display the profiler output\n",
    "rule_output_path = estimator.output_path + estimator.latest_training_job.job_name + \"/rule-output\"\n",
    "! aws s3 ls {rule_output_path} --recursive\n",
    "! aws s3 cp {rule_output_path} ./ --recursive\n",
    "# get the autogenerated folder name of profiler report\n",
    "profiler_report_name = [\n",
    "    rule[\"RuleConfigurationName\"]\n",
    "    for rule in estimator.latest_training_job.rule_job_summary()\n",
    "    if \"Profiler\" in rule[\"RuleConfigurationName\"]\n",
    "][0]\n",
    "IPython.display.HTML(filename=profiler_report_name + \"/profiler-output/profiler-report.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Deploying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Deploy your model to an endpoint\n",
    "predictor = tuner.deploy(initial_instance_count=1, instance_type=\"ml.t2.medium\")\n",
    "# TODO: Add your deployment configuration like instance type and number of instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Run an prediction on the endpoint\n",
    "file = 'data/cifar-10-batches-py/data_batch_1'\n",
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict\n",
    "image=unpickle(file)\n",
    "image=np.reshape(data[b'data'][0], (3, 32, 32))\n",
    "# TODO: Your code to load and preprocess image to send to endpoint for prediction\n",
    "\n",
    "response = predictor.predict(np.expand_dims(data, axis=1))# TODO: Query the endpoint\n",
    "print(response)\n",
    "\n",
    "# image = \n",
    "# response = predictor.predict(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Remember to shutdown/delete your endpoint once your work is done\n",
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 1.8 Python 3.6 GPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/pytorch-1.8-gpu-py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
